{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2301b0554cda45dd88fb5b5317358297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpg', height='240', width='320')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "WARNING:tensorflow:From C:\\Users\\demih\\AppData\\Local\\Temp\\ipykernel_10132\\3817280996.py:51: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "Finish Load Graph..\n",
      "<class 'dict'>\n",
      "dict['Name']:  person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFPS \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(mfps)), (\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    108\u001b[0m image_widget\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m bgr8_to_jpeg(frame)\n\u001b[1;32m--> 110\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xff\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m: \u001b[38;5;66;03m# press 'ESC' to quit\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import the opencv library\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os,time\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_utils\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "# Init camera \n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 320) # set Width\n",
    "cap.set(4, 240) # set Height\n",
    "cap.set(5, 30)  # set Frame rate\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))\n",
    "cap.set(cv2.CAP_PROP_BRIGHTNESS, 40) #Set brightness -64 - 64  0.0\n",
    "cap.set(cv2.CAP_PROP_CONTRAST, 50) #Set contrast -64 - 64  2.0\n",
    "cap.set(cv2.CAP_PROP_EXPOSURE, 156)  #Set exposure 1.0 - 5000  156.0\n",
    "\n",
    "image_widget = widgets.Image(format='jpg', width=320, height=240)\n",
    "##img = mpimg.imread(image_widget)\n",
    "##plt.imshow(img)\n",
    "##plt.axis('off')  # Hide axis labels\n",
    "##plt.show()\n",
    "\n",
    "display(image_widget)\n",
    "\n",
    "# Init tf model\n",
    " \n",
    "MODEL_NAME = \"C:\\\\Users\\\\demih\\\\Downloads\\\\object-detection-template\\\\models\\\\ssdlite_mobilenet_v2_coco_2018_05_09\" #fast\n",
    "PATH_TO_CKPT = MODEL_NAME + '//frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = 'mscoco_label_map.pbtxt'\n",
    "# PATH_TO_LABELS = os.path.join(r'C:\\Users\\demih\\Downloads\\object-detection-template\\object_detection\\data', 'mscoco_label_map.pbtxt') \n",
    "NUM_CLASSES = 90\n",
    "IMAGE_SIZE = (12, 8) \n",
    "fileAlreadyExists = os.path.isfile(PATH_TO_CKPT) \n",
    " \n",
    "if not fileAlreadyExists:\n",
    "    print('Model does not exsist !')\n",
    "    exit\n",
    "\n",
    "\n",
    "# LOAD GRAPH\n",
    "print('Loading...')\n",
    "detection_graph = tf.Graph() \n",
    "with detection_graph.as_default(): \n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid: \n",
    "        serialized_graph = fid.read() \n",
    "        od_graph_def.ParseFromString(serialized_graph) \n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True) \n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print('Finish Load Graph..')\n",
    "\n",
    "print(type(category_index))\n",
    "\n",
    "print(\"dict['Name']: \", category_index[1]['name'])\n",
    "# Main Thread\n",
    "t_start = time.time()\n",
    "fps = 0\n",
    "\n",
    "def bgr8_to_jpeg(image):\n",
    "    _, jpeg = cv2.imencode('.jpg', image)\n",
    "    return jpeg.tobytes()\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "#            frame = cv2.flip(frame, -1) # Flip camera vertically\n",
    "#             frame = cv2.resize(frame,(320,240))\n",
    "            ##############\n",
    "            image_np_expanded = np.expand_dims(frame, axis=0) \n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0') \n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0') \n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0') \n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0') \n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            \n",
    "#             print('Running detection..') \n",
    "            (boxes, scores, classes, num) = sess.run( \n",
    "                [detection_boxes, detection_scores, detection_classes, num_detections], \n",
    "                feed_dict={image_tensor: image_np_expanded}) \n",
    " \n",
    "#             print('Done.  Visualizing..')\n",
    "            vis_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                    frame,\n",
    "                    np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=8)\n",
    "            \n",
    "            for i in range(0, 10):\n",
    "                if scores[0][i] >= 0.5:\n",
    "                    print(category_index[int(classes[0][i])]['name'])\n",
    "            ##############\n",
    "            fps = fps + 1\n",
    "            mfps = fps / (time.time() - t_start)\n",
    "            cv2.putText(frame, \"FPS \" + str(int(mfps)), (10,10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "            image_widget.value = bgr8_to_jpeg(frame)\n",
    "     \n",
    "            k = cv2.waitKey(3000) & 0xff\n",
    "            if k == 27: # press 'ESC' to quit\n",
    "                break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
